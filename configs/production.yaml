# production deployment configuration
# for actual deployment - different from research settings

# api settings
api:
  host: "0.0.0.0"
  port: 8000
  workers: 4  # gunicorn workers
  timeout: 300  # 5 min timeout for long recordings
  max_upload_size: 500  # mb, overnight recording can be big

# model settings
model:
  checkpoint: "models/foundation_v1.pt"
  device: "cuda"  # use gpu if available
  batch_size: 1  # inference is one recording at a time
  use_fp16: true  # faster inference

  # output settings
  return_confidence: true
  return_events: true
  return_spectrogram: false  # dont send back big arrays unless needed

# preprocessing - must match training
preprocessing:
  sample_rate: 16000
  segment_duration: 30.0
  n_mels: 128
  n_fft: 2048
  hop_length: 512
  denoising: "spectral_subtraction"

# database
database:
  url: "postgresql://user:pass@localhost/neendai"
  pool_size: 10
  max_overflow: 20

# redis for caching
redis:
  url: "redis://localhost:6379"
  ttl: 3600  # cache results for 1 hour

# security
security:
  jwt_secret: "${JWT_SECRET}"  # from env var
  token_expiry: 86400  # 24 hours
  rate_limit: 100  # requests per minute per user

# monitoring
monitoring:
  enable_metrics: true
  metrics_port: 9090
  log_level: "INFO"

  # alert thresholds
  alerts:
    error_rate_threshold: 0.05
    latency_p99_threshold: 5000  # ms

# storage
storage:
  recordings_bucket: "neendai-recordings"
  results_bucket: "neendai-results"
  retention_days: 90

# feature flags
features:
  enable_wearable_integration: false  # coming soon
  enable_longitudinal_tracking: false
  enable_pdf_reports: true

# limits
limits:
  max_recording_duration: 36000  # 10 hours
  min_recording_duration: 1800  # 30 minutes
  max_concurrent_jobs: 10
